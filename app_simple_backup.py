"""
CLIP Comparador - Versi√≥n 3.8.1 - OPTIMIZADO PARA 512MB RAM
Sistema de b√∫squeda visual inteligente con modelo RN50 optimizado
"""

import os
import sys
import warnings
warnings.filterwarnings("ignore")

# Importaciones optimizadas para 512MB RAM - LAZY LOADING
import os
import sys
import json
from datetime import datetime
import warnings
warnings.filterwarnings("ignore")

# Variables globales para lazy loading
model = None
preprocess = None
device = None

def lazy_import_heavy_deps():
    """Importar dependencias pesadas solo cuando sea necesario"""
    global torch, clip, np, Image, Flask, render_template, request, jsonify
    global send_from_directory, redirect, url_for, flash, session
    global LoginManager, UserMixin, login_user, login_required, logout_user, current_user
    global Limiter, get_remote_address
    
    try:
        import torch
        import clip  
        import numpy as np
        from PIL import Image
        from flask import Flask, render_template, request, jsonify, send_from_directory, redirect, url_for, flash, session
        from flask_login import LoginManager, UserMixin, login_user, login_required, logout_user, current_user
        from flask_limiter import Limiter
        from flask_limiter.util import get_remote_address
        
        return True
    except ImportError:
        return False

# üè∑Ô∏è Sistema de Versioning Autom√°tico
VERSION = "3.9.6"
BUILD_DATE = "2025-10-02"
CHANGES_LOG = {
    "3.9.6": "FIX EXIF: Corregir import error + detecti√≥n autom√°tica por dimensiones como fallback para m√≥viles",
    "3.9.5": "DEBUG: Logs detallados para diagnosticar problema de orientaci√≥n EXIF en m√≥viles",
    "3.9.4": "FIX EXIF: Evitar doble correcci√≥n orientaci√≥n - solo aplicar en archivos, no en objetos Image ya procesados",
    "3.9.3": "NUEVA FUNCIONALIDAD: Correcci√≥n autom√°tica de orientaci√≥n EXIF para im√°genes de m√≥viles (rotaci√≥n 90¬∞)",
    "3.9.2": "FIX RUTAS IM√ÅGENES: Normalizar separadores \\ a / antes de basename() para compatibilidad Linux/Windows",
    "3.9.1": "FIX COMPLETO JSON: Convertir float32 en calculate_similarity y results para evitar errores serializaci√≥n",
    "3.9.0": "FIX JSON SERIALIZATION: Convertir float32 PyTorch a float Python para evitar error 'not JSON serializable'",
    "3.8.9": "FIX CR√çTICO CATEGOR√çAS: Corregido bucle classifications + generadas product_classifications.json para detecci√≥n de productos",
    "3.8.8": "FIX DETECCI√ìN CATEGOR√çAS: Mejorada l√≥gica para detectar 'camisa' en 'camisa con botones y cuello'",
    "3.8.7": "FIX COMPATIBILIDAD: Removido half precision problem√°tico + estado de modelo corregido",
    "3.8.6": "CORRECCI√ìN CR√çTICA: RN50 (244MB) en lugar de ViT-B/32 (338MB) - Error de tama√±os de modelos",
    "3.8.5": "OPTIMIZACI√ìN MEMORIA: Sistema optimizado para 512MB RAM con lazy loading y garbage collection",
    "3.8.0": "DETECCI√ìN AMPLIADA: Agregadas categor√≠as no comercializadas para correcta identificaci√≥n",
    "3.7.0": "ENFOQUE SIMPLIFICADO: Verificaci√≥n gen√©rica de categor√≠as comercializadas vs no comercializadas"
}

def show_version_info():
    """Mostrar informaci√≥n de versi√≥n"""
    pass

# Configuraci√≥n de la aplicaci√≥n Flask (lazy loading de dependencias)
def create_app():
    """Crear aplicaci√≥n Flask con lazy loading"""
    if not lazy_import_heavy_deps():
        raise Exception("No se pudieron cargar las dependencias")
    
    app = Flask(__name__)
    app.config['CATALOGO_FOLDER'] = 'catalogo'
    app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size
    app.config['SECRET_KEY'] = os.environ.get('SECRET_KEY', 'clip-demo-secret-key-2025')
    
    return app

# Crear app
app = create_app()

# Configuraci√≥n de autenticaci√≥n
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = 'login'
login_manager.login_message = 'Por favor, inicia sesi√≥n para acceder.'

# Configuraci√≥n de rate limiting
limiter = Limiter(
    key_func=get_remote_address,
    default_limits=["200 per day", "50 per hour", "10 per minute"]
)
limiter.init_app(app)

# Usuarios demo
DEMO_USERS = {
    'demo': 'clipdemo2025',
    'cliente': 'visual2025',
    'admin': 'clipadmin2025'
}

class User(UserMixin):
    def __init__(self, username):
        self.id = username
        self.username = username

@login_manager.user_loader
def load_user(user_id):
    if user_id in DEMO_USERS:
        return User(user_id)
    return None

# Variables globales
model = None
preprocess = None
device = None
catalog_embeddings = {}

def ensure_model_loaded():
    """Asegurar que el modelo est√© cargado (lazy loading)"""
    global model, preprocess, device
    if model is None:
        load_clip_model()
    return model is not None

def load_clip_model():
    """Cargar el modelo CLIP con lazy loading y optimizaciones de memoria"""
    global model, preprocess, device
    
    # Lazy import de dependencias pesadas
    if not lazy_import_heavy_deps():
        return None, None
    
    try:
        # Configurar dispositivo (forzar CPU para ahorrar memoria)
        device = "cpu"  # Forzar CPU para 512MB RAM
        
        # Usar RN50 que sabemos que es m√°s peque√±o
        model, preprocess = clip.load("RN50", device=device)
        
        # Optimizaciones de memoria (sin half precision para compatibilidad)
        if hasattr(model, 'eval'):
            model.eval()
        
        # Forzar garbage collection agresivo
        import gc
        gc.collect()
        
        return model, preprocess
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return None, None

def get_image_embedding(image_input):
    """Generar embedding para una imagen - acepta path o objeto PIL Image"""
    global model, preprocess, device
    
    # Asegurar que el modelo est√© cargado
    if not ensure_model_loaded():
        raise Exception("No se pudo cargar el modelo CLIP")
    
    try:
        # Determinar si es un path o un objeto Image
        if isinstance(image_input, str):
            image = Image.open(image_input)
            # Corregir orientaci√≥n EXIF solo para archivos (no para objetos ya procesados)
            image = fix_image_orientation(image)
        else:
            image = image_input
            
        image = image.convert('RGB')
        
        # Redimensionar imagen agresivamente para ahorrar memoria
        max_size = 224  # M√≠nimo posible para ViT-B/32
        image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
        
        # Preprocesar (batch size 1 para memoria m√≠nima)
        image_tensor = preprocess(image).unsqueeze(0).to(device)
        
        # Liberar imagen original inmediatamente
        del image
        import gc
        gc.collect()
        
        # Generar embedding con optimizaciones de memoria EXTREMAS
        with torch.no_grad():
            # Asegurar compatibilidad de tipos - siempre usar float32 para estabilidad
            image_tensor = image_tensor.float()  # Forzar float32 para compatibilidad
            
            image_features = model.encode_image(image_tensor)
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
            
            # Liberar tensor inmediatamente
            embedding = image_features.cpu().numpy().flatten().astype(np.float32)
            
            # Limpiar todo inmediatamente
            del image_tensor, image_features
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            gc.collect()
        
        return embedding
        
    except Exception as e:
        # Limpiar memoria en caso de error
        import gc
        gc.collect()
        return None

def load_catalog_embeddings():
    """Cargar embeddings del cat√°logo desde archivo"""
    global catalog_embeddings
    embeddings_file = "catalogo/embeddings.json"
    try:
        with open(embeddings_file, 'r') as f:
            embeddings_data = json.load(f)
        
        catalog_embeddings = {}
        for filename, embedding_list in embeddings_data.items():
            catalog_embeddings[filename] = np.array(embedding_list, dtype=np.float32)
        
        return True
    except FileNotFoundError:
        return False
    except Exception:
        return False

def calculate_similarity(embedding1, embedding2):
    """Calcular similitud coseno entre dos embeddings"""
    similarity = np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))
    return float(similarity)  # Convertir a float Python para JSON serialization

def fix_image_orientation(image):
    """Corregir orientaci√≥n de imagen bas√°ndose en datos EXIF (especialmente para m√≥viles)"""
    try:
        # M√©todo 1: Intentar usar EXIF
        try:
            exif = image._getexif()
            if exif is not None:
                orientation = exif.get(274, 1)  # Default a 1 si no existe
                
                if orientation == 3:
                    image = image.rotate(180, expand=True)
                elif orientation == 6:
                    image = image.rotate(270, expand=True)
                elif orientation == 8:
                    image = image.rotate(90, expand=True)
                
                return image
        except Exception:
            pass
        
        # M√©todo 2: Detecci√≥n autom√°tica por dimensiones (FALLBACK)
        width, height = image.size
        if width > height and width > 3000:  # Imagen grande y horizontal mal orientada
            image = image.rotate(90, expand=True)
            
    except Exception:
        pass
    
    return image

def classify_query_image(image_input):
    """Clasificar imagen usando CLIP text embeddings - acepta path o objeto PIL Image"""
    global model, preprocess, device
    try:
        # Determinar si es un path o un objeto Image
        if isinstance(image_input, str):
            image = Image.open(image_input)
            # Corregir orientaci√≥n EXIF solo para archivos (no para objetos ya procesados)
            image = fix_image_orientation(image)
        else:
            image = image_input
            
        image = image.convert('RGB')
            
        image_tensor = preprocess(image).unsqueeze(0).to(device)
        
        # Categor√≠as UNIFICADAS - 12 CATEGOR√çAS DEL SISTEMA + CATEGOR√çAS NO COMERCIALIZADAS
        categories = [
            # ===== CATEGOR√çAS COMERCIALIZADAS POR GOODY =====
            "buzo cerrado con capucha, sudadera gruesa de trabajo, hoodie with zipper",
            "camisa con botones y cuello, blusa formal de trabajo, dress shirt with collar",
            "gorro de chef, gorra profesional con visera, work cap with brim, boina calada",
            "chaqueta cerrada profesional, jacket with zipper, campera de trabajo",
            "delantal de trabajo con pechera, mandil profesional con tirantes, apron with straps green",
            "ambo m√©dico scrubs sanitario, uniforme hospitalario, medical uniform set",
            "casaca de chef blanca, chaqueta de cocina profesional, chef jacket with buttons",
            "zapato cerrado profesional, zueco de trabajo, calzado antideslizante, work shoes",
            "cardigan abierto con botones, chaleco sin mangas, vest without sleeves",
            "remera polo casual, camiseta deportiva sin botones, t-shirt casual cotton",
            "buzo frizado de trabajo, sudadera cerrada profesional, thick work sweatshirt",
            "conjunto deportivo casual, ropa de gimnasio, activewear clothing set",
            # ===== CATEGOR√çAS NO COMERCIALIZADAS (PARA DETECCI√ìN Y RECHAZO) =====
            "pantal√≥n largo, jean de trabajo, pants trousers long legs black",
            "short bermuda corto, pantal√≥n corto de verano, summer shorts",
            "falda de vestir, pollera profesional, skirt for women",
            "vestido de trabajo, dress for women, ropa femenina formal",
            "chaqueta de punto abierta, cardigan profesional, open front sweater"
        ]
        
        # Tokenizar categor√≠as
        text_tokens = clip.tokenize(categories).to(device)
        
        with torch.no_grad():
            # Obtener embeddings de imagen y texto
            image_features = model.encode_image(image_tensor)
            text_features = model.encode_text(text_tokens)
            
            # Normalizar
            image_features /= image_features.norm(dim=-1, keepdim=True)
            text_features /= text_features.norm(dim=-1, keepdim=True)
            
            # Calcular similitudes
            similarities = (image_features @ text_features.T).squeeze(0)
            
            # Obtener la categor√≠a m√°s probable
            best_match_idx = similarities.argmax().item()
            confidence = float(similarities[best_match_idx].item())  # Convertir a float de Python
            
            category = categories[best_match_idx].split(',')[0].strip()
            
            # UMBRAL M√çNIMO DE CONFIANZA - Si es muy bajo, no hay match claro
            MIN_CONFIDENCE_THRESHOLD = 0.20  # 20% m√≠nimo para considerar v√°lida la detecci√≥n
            
            if confidence < MIN_CONFIDENCE_THRESHOLD:
                return None, confidence
            
            return category, confidence
            
    except Exception:
        return None, 0.0

def find_similar_images(query_embedding, top_k=3, query_type=None, query_confidence=0.0):
    """
    VERSI√ìN 3.3.0: MODOS INTELIGENTES COMPLETOS 
    Sistema espec√≠fico para todas las 12 categor√≠as profesionales
    """
    
    if not catalog_embeddings or query_embedding is None:
        return []

    # PASO 1: Calcular similitudes visuales base
    similarities = []
    for filename, catalog_embedding in catalog_embeddings.items():
        visual_similarity = calculate_similarity(query_embedding, catalog_embedding)
        similarities.append((filename, visual_similarity))

    # PASO 2: Cargar clasificaciones
    try:
        with open('catalogo/product_classifications.json', 'r', encoding='utf-8') as f:
            classifications = json.load(f)
    except:
        classifications = {}

    # PASO 3: SISTEMA DE MODOS INTELIGENTES COMPLETO CON VERIFICACI√ìN DE DISPONIBILIDAD
    results = []
    
    # VERIFICAR SI HAY CATEGOR√çA V√ÅLIDA DETECTADA
    if not query_type:
        return []
    
    # =================== CATEGOR√çA: BUZOS (Evaluar ANTES que gorros) ===================
    if query_type and any(word in query_type.lower() for word in ["buzo", "hoodie", "sudadera", "frizado"]):
        # Verificar disponibilidad antes de buscar
        has_products, _ = _check_category_availability("buzo", classifications)
        if not has_products:
            return []
        results = _filter_category_strict(similarities, classifications,
                                          ["BUZO", "HOODIE", "SUDADERA", "FRIZADO"], "üèÉ", 0.65, top_k)
    
    # =================== CATEGOR√çA: CAMISAS ===================
    elif query_type and any(word in query_type.lower() for word in ["camisa", "shirt"]):
        has_products, _ = _check_category_availability("camisa", classifications)
        if not has_products:
            return []
        results = _filter_category_intelligent(similarities, classifications, 
                                               ["CAMISA", "SHIRT"], "üëî", 0.65, top_k)
    
    # =================== CATEGOR√çA: GORROS/GORRAS (Despu√©s de buzos) ===================
    elif query_type and any(word in query_type.lower() for word in ["gorro", "gorra", "cap", "hat", "boina"]) and "buzo" not in query_type.lower():
        
        has_products, _ = _check_category_availability("gorro", classifications)
        if not has_products:
            return []
        results = _filter_category_strict(similarities, classifications,
                                          ["GORRO", "GORRA", "CAP", "HAT", "BOINA"], "üß¢", 0.60, top_k)
    
    # =================== CATEGOR√çA: CHAQUETAS ===================
    elif query_type and any(word in query_type.lower() for word in ["chaqueta", "jacket"]):
        
        has_products, _ = _check_category_availability("chaqueta", classifications)
        if not has_products:
            return []
        results = _filter_category_intelligent(similarities, classifications,
                                               ["CHAQUETA", "JACKET", "CAMISA", "CASACA", "CARDIGAN", "AMBO"], "üß•", 0.65, top_k)
    
    # =================== CATEGOR√çA: DELANTALES ===================
    elif query_type and any(word in query_type.lower() for word in ["delantal", "mandil", "pechera"]):
        
        has_products, _ = _check_category_availability("delantal", classifications)
        if not has_products:
            return []
        results = _filter_category_strict(similarities, classifications,
                                          ["DELANTAL", "MANDIL", "PECHERA", "JUMPER"], "ü•Ω", 0.60, top_k)
    
    # =================== CATEGOR√çA: AMBOS ===================
    elif query_type and any(word in query_type.lower() for word in ["ambo", "uniforme medico", "scrub"]):
        
        has_products, _ = _check_category_availability("ambo", classifications)
        if not has_products:
            return []
        results = _filter_category_intelligent(similarities, classifications,
                                               ["AMBO", "UNIFORME", "SCRUB", "CASACA"], "üè•", 0.65, top_k)
    
    # =================== CATEGOR√çA: CASACAS ===================
    elif query_type and any(word in query_type.lower() for word in ["casaca", "blazer"]):
        
        has_products, _ = _check_category_availability("casaca", classifications)
        if not has_products:
            return []
        results = _filter_category_intelligent(similarities, classifications,
                                               ["CASACA", "BLAZER", "CHAQUETA", "CAMISA"], "ü§µ", 0.65, top_k)
    
    # =================== CATEGOR√çA: CALZADO ===================
    elif query_type and any(word in query_type.lower() for word in ["zapato", "zueco", "calzado", "shoe"]):
        
        has_products, _ = _check_category_availability("zapato", classifications)
        if not has_products:
            return []
        results = _filter_category_strict(similarities, classifications,
                                          ["ZAPATO", "ZUECO", "CALZADO", "SHOE"], "üëü", 0.60, top_k)
    
    # =================== CATEGOR√çA: CARDIGANS ===================
    elif query_type and any(word in query_type.lower() for word in ["cardigan", "chaleco", "vest"]):
        
        has_products, _ = _check_category_availability("cardigan", classifications)
        if not has_products:
            return []
        results = _filter_category_strict(similarities, classifications,
                                          ["CARDIGAN", "CHALECO", "VEST"], "üß∂", 0.65, top_k)
    
    # =================== CATEGOR√çA: REMERAS ===================
    elif query_type and any(word in query_type.lower() for word in ["remera", "polo", "t-shirt", "playera"]):
        
        has_remeras, _ = _check_category_availability("remera", classifications)
        
        if has_remeras:
            # Si hay remeras, buscar solo remeras
            results = _filter_category_strict(similarities, classifications,
                                              ["REMERA", "POLO", "T-SHIRT", "PLAYERA"], "üëï", 0.65, top_k)
        else:
            # Si no hay remeras, buscar en camisas (visualmente similares)
            has_camisas, _ = _check_category_availability("camisa", classifications)
            if has_camisas:
                results = _filter_category_strict(similarities, classifications,
                                                  ["CAMISA", "SHIRT", "BLUSA"], "üëî", 0.60, top_k)
            else:
                return []
    
    # =================== MODO GENERAL (Para categor√≠as no mapeadas espec√≠ficamente) ===================
    else:
        results = _apply_general_search(similarities, classifications, query_type, query_confidence, top_k)

    # PASO 4: Verificar resultados finales Y CALIDAD DE SIMILITUD
    if not results:
        return []

    # VERIFICACI√ìN DE SIMILITUD VISUAL M√çNIMA - Nueva funci√≥n v3.7.0
    max_similarity = max(score for _, score in results)
    avg_similarity = sum(score for _, score in results) / len(results)
    
    MIN_VISUAL_SIMILARITY = 0.60  # 60% m√≠nimo para considerar relevante
    
    if max_similarity < MIN_VISUAL_SIMILARITY:
        return []
    
    if avg_similarity < 0.45:  # Promedio muy bajo indica mala clasificaci√≥n
        return []

    return results

def _filter_category_strict(similarities, classifications, keywords, emoji, threshold, top_k):
    """Filtrado estricto: solo productos de la categor√≠a espec√≠fica - M√ÅXIMO 3 RESULTADOS"""
    all_category_items = []  # Todos los items de la categor√≠a
    
    for filename, visual_sim in similarities:
        basename = os.path.basename(filename)
        is_category = False
        
        # Verificar por nombre
        if any(word in basename.upper() for word in keywords):
            is_category = True
        # Verificar por clasificaci√≥n
        elif basename in classifications:
            cat = classifications[basename]['category'].lower()
            if any(word.lower() in cat for word in keywords):
                is_category = True
        
        if is_category:
            all_category_items.append((filename, visual_sim))
    
    # SI NO HAY PRODUCTOS DE LA CATEGOR√çA, RETORNAR VAC√çO
    if not all_category_items:
        return []
    
    # Ordenar por similitud (mayor a menor)
    all_category_items.sort(key=lambda x: x[1], reverse=True)
    
    # SIEMPRE devolver los TOP 3 de la categor√≠a (o los que haya si son menos)
    results = all_category_items[:top_k]
    
    # Mostrar los resultados seleccionados
    for filename, visual_sim in results:
        basename = os.path.basename(filename)
    
    return results

def _filter_category_intelligent(similarities, classifications, keywords, emoji, threshold, top_k):
    """Filtrado inteligente: categor√≠a principal + productos relacionados con boost"""
    category_products = []
    related_products = []
    
    for filename, visual_sim in similarities:
        basename = os.path.basename(filename)
        is_main_category = False
        is_related = False
        
        # Verificar categor√≠a principal (primer keyword)
        main_keyword = keywords[0]
        if main_keyword in basename.upper():
            is_main_category = True
        elif basename in classifications:
            cat = classifications[basename]['category'].lower()
            if main_keyword.lower() in cat:
                is_main_category = True
        
        # Verificar categor√≠as relacionadas
        if not is_main_category:
            if any(word in basename.upper() for word in keywords[1:]):
                is_related = True
            elif basename in classifications:
                cat = classifications[basename]['category'].lower()
                if any(word.lower() in cat for word in keywords[1:]):
                    is_related = True
        
        if is_main_category:
            # Boost para categor√≠a principal
            boosted_score = min(0.99, visual_sim * 1.15)
            category_products.append((filename, boosted_score))
        elif is_related:
            # Productos relacionados sin penalizaci√≥n excesiva
            related_products.append((filename, visual_sim))
    
    # Combinar resultados priorizando categor√≠a principal
    all_products = category_products + related_products
    all_products.sort(key=lambda x: x[1], reverse=True)
    
    results = [(f, s) for f, s in all_products if s > threshold][:top_k]
    
    return results

def _check_category_availability(query_type, classifications):
    """Verificar si la categor√≠a detectada corresponde a productos comercializados por GOODY"""
    if not query_type:
        return True, []
    
    query_lower = query_type.lower()
    available_products = []
    
    # Mapeo de categor√≠as V√ÅLIDAS (productos que S√ç comercializa GOODY)
    goody_category_mappings = {
        'buzo': ['BUZO', 'BUZOS', 'SUDADERA', 'HOODIE', 'FRIZADO'],
        'camisa': ['CAMISA', 'CAMISAS', 'CAMISAS HOMBRE- DAMA', 'BLUSA', 'SHIRT'],
        'gorro': ['GORRO', 'GORROS', 'GORROS ‚Äì GORRAS', 'GORRA', 'BOINA', 'CAP'],
        'chaqueta': ['CHAQUETA', 'CHAQUETAS', 'JACKET', 'CAMPERA'],
        'delantal': ['DELANTAL', 'MANDIL', 'APRON', 'PECHERA', 'JUMPER'],
        'ambo': ['AMBO', 'AMBO VESTIR HOMBRE ‚Äì DAMA', 'SCRUBS', 'UNIFORME'],
        'casaca': ['CASACA', 'CASACAS', 'CHEF'],
        'zapato': ['ZAPATO', 'ZAPATO DAMA', 'ZUECO', 'ZUECOS', 'CALZADO', 'SHOE'],
        'cardigan': ['CARDIGAN', 'CARDIGAN HOMBRE ‚Äì DAMA', 'CHALECO', 'CHALECO DAMA- HOMBRE', 'VEST'],
        'remera': ['REMERA', 'REMERAS', 'POLO', 'T-SHIRT', 'PLAYERA']
    }
    
    # Mapeo de categor√≠as NO COMERCIALIZADAS (productos que NO vende GOODY)
    non_commercialized_mappings = {
        'pantal√≥n': ['PANTALON', 'JEAN', 'PANTS', 'TROUSERS'],
        'short': ['SHORT', 'BERMUDA', 'SHORTS'],
        'falda': ['FALDA', 'POLLERA', 'SKIRT'],
        'vestido': ['VESTIDO', 'DRESS'],
    }
    
    # Verificar si la categor√≠a detectada corresponde a productos comercializados
    category_found = False
    relevant_keywords = []
    is_non_commercialized = False
    
    # PASO 1: Verificar si es una categor√≠a COMERCIALIZADA
    for goody_category, keywords in goody_category_mappings.items():
        # Buscar si alguna palabra clave de la categor√≠a est√° en el query
        if any(keyword.lower() in query_lower for keyword in [goody_category] + keywords):
            category_found = True
            relevant_keywords = keywords
            
            break
    
    # PASO 2: Si no es comercializada, verificar si es NO COMERCIALIZADA
    if not category_found:
        for non_comm_category, keywords in non_commercialized_mappings.items():
            # Buscar si alguna palabra clave de categor√≠a no comercializada est√° en el query
            if any(keyword.lower() in query_lower for keyword in [non_comm_category] + keywords):
                is_non_commercialized = True
                
                
                
                return False, []
                break
    
    # Si no encontramos la categor√≠a en ning√∫n mapeo, es categor√≠a desconocida
    if not category_found and not is_non_commercialized:
        
        
        return False, []
    
    # Buscar productos disponibles en el cat√°logo para esta categor√≠a v√°lida
    for basename in classifications:
        # Verificar por nombre del archivo
        if any(keyword in basename.upper() for keyword in relevant_keywords):
            available_products.append(basename)
            continue
            
        # Verificar por categor√≠a clasificada
        catalog_category = classifications[basename]['category'].upper()
        if any(keyword in catalog_category for keyword in relevant_keywords):
            available_products.append(basename)
    
    has_products = len(available_products) > 0
    
    return has_products, available_products

def _apply_general_search(similarities, classifications, query_type, query_confidence, top_k):
    """B√∫squeda general con verificaci√≥n de categor√≠as disponibles"""
    
    # VERIFICAR SI ES UNA CATEGOR√çA NO COMERCIALIZADA POR GOODY
    if query_type and query_confidence > 0.2:
        has_products, available_products = _check_category_availability(query_type, classifications)
        
        if not has_products:
            
            
            return []
    
    
    
    # Aplicar boost categ√≥rico ligero si hay buena confianza
    if query_type and query_confidence > 0.4:
        boosted_similarities = []
        for filename, visual_sim in similarities:
            basename = os.path.basename(filename)
            final_score = visual_sim
            
            if basename in classifications:
                catalog_category = classifications[basename]['category'].lower()
                if query_type.lower() in catalog_category or catalog_category in query_type.lower():
                    boost_factor = 1.1  # 10% boost ligero
                    final_score = min(0.99, visual_sim * boost_factor)
                    
            
            boosted_similarities.append((filename, final_score))
        
        similarities = boosted_similarities
    
    # Aplicar umbral general: solo productos con similitud > 65%
    similarities.sort(key=lambda x: x[1], reverse=True)
    results = [(f, s) for f, s in similarities if s > 0.65][:top_k]
    
    return results

def _get_display_category(basename, classifications):
    """Obtener categor√≠a para mostrar en resultados"""
    if basename in classifications:
        return classifications[basename]['category'][:8].upper()
    else:
        # Inferir por nombre
        if "CAMISA" in basename.upper(): return "CAMISA"
        elif "CHAQUETA" in basename.upper(): return "CHAQUETA"
        elif "DELANTAL" in basename.upper(): return "DELANTAL"
        elif "AMBO" in basename.upper(): return "AMBO"
        elif "CASACA" in basename.upper(): return "CASACA"
        elif "GORRO" in basename.upper() or "GORRA" in basename.upper(): return "GORRO"
        elif "CARDIGAN" in basename.upper() or "CHALECO" in basename.upper(): return "CARDIGAN"
        elif "BUZO" in basename.upper(): return "BUZO"
        elif "REMERA" in basename.upper(): return "REMERA"
        elif "ZAPATO" in basename.upper() or "ZUECO" in basename.upper(): return "CALZADO"
        else: return "OTROS"

# ==================== RUTAS DE AUTENTICACI√ìN ====================

@app.route('/login', methods=['GET', 'POST'])
@limiter.limit("5 per minute")
def login():
    """P√°gina de login"""
    if current_user.is_authenticated:
        return redirect(url_for('index'))
    
    if request.method == 'POST':
        username = request.form['username']
        password = request.form['password']
        
        if username in DEMO_USERS and DEMO_USERS[username] == password:
            user = User(username)
            login_user(user)
            next_page = request.args.get('next')
            return redirect(next_page) if next_page else redirect(url_for('index'))
        else:
            flash('Usuario o contrase√±a incorrectos')
            return render_template('login.html', error='Usuario o contrase√±a incorrectos')
    
    return render_template('login.html')

@app.route('/logout')
@login_required
def logout():
    """Cerrar sesi√≥n"""
    logout_user()
    return redirect(url_for('login'))

# ==================== RUTAS PRINCIPALES ====================

@app.route('/')
@login_required
def index():
    """P√°gina principal"""
    return render_template('index.html', user=current_user.username)

@app.route('/upload', methods=['POST'])
@login_required
@limiter.limit("20 per minute")
def upload_file():
    """Procesar imagen subida y encontrar similares - SIN GUARDAR EN DISCO"""
    try:
        
        
        if 'file' not in request.files:
            
            return jsonify({'error': 'No se seleccion√≥ archivo'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'No se seleccion√≥ archivo'}), 400
        
        
        
        # Procesar imagen directamente desde memoria (SIN GUARDAR)
        try:
            # Leer el contenido completo primero
            file_content = file.read()
            file_size = len(file_content)
            
            
            # Crear un stream desde el contenido
            import io
            image_stream = io.BytesIO(file_content)
            image = Image.open(image_stream)
            
            
            # Corregir orientaci√≥n EXIF (especialmente importante para m√≥viles)
            
            image = fix_image_orientation(image)
            image = image.convert('RGB')
            
            
            # Convertir imagen a base64 para mostrar en frontend
            import base64
            img_buffer = io.BytesIO()
            image.save(img_buffer, format='JPEG', quality=85)
            img_base64 = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
            uploaded_image_data = f"data:image/jpeg;base64,{img_base64}"
            
        except Exception as e:
            
            return jsonify({'error': 'Error procesando imagen'}), 500
        
        # Procesar imagen
        query_embedding = get_image_embedding(image)
        
        if query_embedding is None:
            return jsonify({'error': 'Error procesando imagen'}), 500
        
        # Clasificar autom√°ticamente
        query_type, query_confidence = classify_query_image(image)
        
        # Buscar im√°genes similares
        similar_images = find_similar_images(
            query_embedding, 
            top_k=3, 
            query_type=query_type, 
            query_confidence=query_confidence
        )
        
        
        
        # Preparar respuesta
        results = []
        for filename_path, similarity in similar_images:
            # Asegurar que solo tengamos el nombre del archivo (sin path)
            # Manejar tanto \ (Windows) como / (Linux) separadores
            basename = os.path.basename(filename_path.replace('\\', '/'))
            sim_float = float(similarity)  # Convertir a float Python primero
            results.append({
                'filename': basename,
                'similarity': sim_float,
                'similarity_percent': round(sim_float * 100, 2)
            })
        
        # Determinar mensaje de estado
        status_message = None
        if not similar_images:
            if query_confidence < 0.20:  # Umbral muy bajo
                status_message = f"La imagen no coincide suficientemente con ninguna categor√≠a conocida (confianza: {query_confidence*100:.1f}%)"
            else:
                # Verificar si la categor√≠a detectada tiene productos disponibles
                try:
                    with open('catalogo/product_classifications.json', 'r', encoding='utf-8') as f:
                        classifications = json.load(f)
                    has_products, _ = _check_category_availability(query_type, classifications)
                    if not has_products:
                        status_message = f"GOODY no comercializa productos de la categor√≠a '{query_type}'. Las categor√≠as disponibles son: BUZO, CAMISA, GORRO, CHAQUETA, DELANTAL, AMBO, CASACA, CALZADO, CARDIGAN, REMERA"
                    else:
                        # Verificar si fue rechazado por similitud insuficiente
                        status_message = f"La imagen no muestra suficiente similitud visual con productos de la categor√≠a '{query_type}'. Esto sugiere que podr√≠a ser un producto no comercializado por GOODY."
                except:
                    status_message = "No se encontraron productos similares en el cat√°logo"
        
        response_data = {
            'uploaded_file': file.filename,  # Solo nombre, no se guarda
            'uploaded_image_data': uploaded_image_data,  # Imagen en base64
            'query_type': query_type,
            'query_confidence': round(query_confidence, 3),
            'similar_images': results,
            'status_message': status_message
        }
        
        
        
        return jsonify(response_data)
        
    except Exception as e:
        
        return jsonify({'error': str(e)}), 500

@app.route('/status')
def status():
    """Estado del sistema - Sin auth para health checks"""
    # Determinar estado real del modelo
    model_status = "No cargado"
    model_really_loaded = False
    
    try:
        if model is not None:
            model_status = "Cargado y listo"
            model_really_loaded = True
        else:
            # Verificar si las dependencias est√°n disponibles
            if lazy_import_heavy_deps():
                model_status = "Disponible (lazy loading)"
                model_really_loaded = False
            else:
                model_status = "Error - dependencias no disponibles"
                model_really_loaded = False
    except Exception as e:
        model_status = f"Error: {str(e)}"
        model_really_loaded = False
    
    return jsonify({
        'version': VERSION,
        'build_date': BUILD_DATE,
        'model_loaded': model_really_loaded,
        'model_status': model_status,
        'catalog_size': len(catalog_embeddings),
        'device': str(device) if device else "None"
    })

@app.route('/catalogo/<filename>')
@login_required
def catalog_file(filename):
    """Servir archivos del cat√°logo"""
    return send_from_directory(app.config['CATALOGO_FOLDER'], filename)

@app.route('/admin/generate-embeddings', methods=['GET', 'POST'])
def generate_embeddings_endpoint():
    """Generar embeddings del cat√°logo disponible - Sin auth para setup inicial"""
    try:
        # Asegurar que el modelo est√© cargado
        if not ensure_model_loaded():
            return jsonify({'error': 'No se pudo cargar el modelo CLIP'}), 500
            
        catalog_path = app.config['CATALOGO_FOLDER']
        if not os.path.exists(catalog_path):
            return jsonify({'error': 'Directorio cat√°logo no encontrado'}), 404
            
        # Importar y ejecutar generaci√≥n de embeddings
        import subprocess
        result = subprocess.run([sys.executable, 'generate_embeddings.py'], 
                               capture_output=True, text=True, cwd='.')
        
        if result.returncode == 0:
            # Recargar embeddings
            load_catalog_embeddings()
            return jsonify({
                'success': True,
                'message': f'Embeddings generados para {len(catalog_embeddings)} im√°genes',
                'catalog_size': len(catalog_embeddings)
            })
        else:
            return jsonify({'error': f'Error generando embeddings: {result.stderr}'}), 500
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def initialize_system():
    """Inicializar sistema con lazy loading"""
    show_version_info()
    
    # Probar que el modelo se puede cargar (pero no mantenerlo en memoria)
    test_success = False
    try:
        if lazy_import_heavy_deps():
            # Hacer una prueba r√°pida de carga sin mantener el modelo
            import torch
            import clip
            device_test = "cpu"
            model_test, _ = clip.load("RN50", device=device_test)
            if model_test is not None:
                test_success = True
                # Limpiar memoria inmediatamente
                del model_test
                import gc
                gc.collect()
    except Exception:
        pass
    
    # Cargar embeddings del cat√°logo (sin requerir modelo)
    load_catalog_embeddings()
    
    return True

if __name__ == '__main__':
    if initialize_system():
        # Puerto din√°mico para despliegue en cloud (Render, Heroku, etc.)
        port = int(os.environ.get('PORT', 5000))
        app.run(host='0.0.0.0', port=port, debug=False)
    else:
        sys.exit(1)
